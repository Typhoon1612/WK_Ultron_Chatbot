{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5790c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"what\" in query_lemmas and \"is\" in query_lemmas:\n",
    "                if not names:\n",
    "                    return \"I'm sorry, I didn't catch your name. Can you please tell me your name?\"\n",
    "            else:\n",
    "                return responses[\"my_name\"][0].format(name=names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e42c0ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our customer service chatbot!\n",
      "You: Booking\n",
      "Chatbot: You may proceed to FishAirline.com for booking!\n",
      "You: Reserve\n",
      "Chatbot: You may proceed to FishAirline.com for booking!\n",
      "You: purchase\n",
      "Chatbot: You may proceed to FishAirline.com for booking!\n",
      "You: Where can I purchase a ticket?\n",
      "Chatbot: You may proceed to FishAirline.com for booking!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3004\\3574592102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m# Run the chatbot function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m \u001b[0mchatbot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3004\\3574592102.py\u001b[0m in \u001b[0;36mchatbot\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Welcome to our customer service chatbot!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"exit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Define a list of possible responses to customer queries\n",
    "responses = {\n",
    "    \"greeting\": [\"Hello, how may I assist you?\", \"Welcome, how can I help you today?\"],\n",
    "    \"booking\": [\"You may proceed to FishAirline.com for booking!\"],\n",
    "    \"support_channel\": [\"You can contact our support team at support@example.com or by calling 1-800-123-4567.\"],\n",
    "    \"available-country\": [\"\\nOur flights only operate within Southeast Asian countries.\\nWhich only included:\\n1. Brunei\\n2. Cambodia\\n3. Indonesia\\n4. Laos\\n5. Malaysia\\n6. Myanmar\\n7. Philippines\\n8. Singapore\\n9. Thailand\\n10. Timor-Leste\\n11. Vietnam\"],\n",
    "    \"country_name\": [\"Fuck {country_name} people\"],\n",
    "    \"not_understand\": [\"Fuck you, humans, please type something that I can understand\", \"I'm sorry, I didn't understand your query. Please try again.\"],\n",
    "    \"packages\": [\"2 Way Tickets\", \"1 Way Tickets\"],\n",
    "    \"user_Intro\": [\"Hello {name}\"],\n",
    "    \"my_name\": [\"Your name is {name}\"],\n",
    "    \"task\": [\"Sure, let me assist you with that. Please provide your account information and I'll reset your password for you.\",\n",
    "             \"I can definitely help you with that. Please give me a moment to update your account information.\"],\n",
    "    \"feedback\": [\"Thank you for your feedback. We'll take that into consideration as we continue to improve our services.\", \n",
    "                 \"We appreciate your feedback and will use it to improve our products and services.\"]\n",
    "}\n",
    "\n",
    "# Create a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "name = \"\"\n",
    "asean_countries = {'Brunei', 'Cambodia', 'Indonesia', 'Laos', 'Malaysia', 'Myanmar', 'Philippines', 'Singapore', 'Thailand', 'Vietnam'}\n",
    "\n",
    "# Define a function to lemmatize a given sentence\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join the lemmatized words back into a sentence\n",
    "    lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# Define a function to extract names from a sentence\n",
    "def extract_names(query):\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(query)\n",
    "    # Tag the words with their part of speech\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    # Extract the named entities from the tagged words\n",
    "    named_entities = nltk.ne_chunk(tagged_words)\n",
    "    # Filter out non-person named entities\n",
    "    person_entities = [entity for entity in named_entities if isinstance(entity, nltk.tree.Tree) and entity.label() == \"PERSON\"]\n",
    "    # Extract the person names from the person named entities\n",
    "    person_names = [ \" \".join([word[0] for word in entity.leaves()]) for entity in person_entities]\n",
    "    return person_names\n",
    "\n",
    "def extract_country_names(query):\n",
    "    # tokenize the text\n",
    "    tokens = nltk.word_tokenize(query)\n",
    "\n",
    "    # use Part-of-Speech (POS) tagging to tag the words with their part of speech\n",
    "    tagged_words = nltk.pos_tag(tokens)\n",
    "\n",
    "    # use Named Entity Recognition (NER) to label the named entities in the text\n",
    "    ner_tagged = nltk.ne_chunk(tagged_words)\n",
    "\n",
    "    # Filter out non-person named entities\n",
    "    country_entities = [entity for entity in ner_tagged if isinstance(entity, nltk.tree.Tree) and entity.label() == \"GPE\"]\n",
    "    # Extract the person names from the person named entities\n",
    "    country_names = [ \" \".join([word[0] for word in entity.leaves()]) for entity in country_entities]\n",
    "    return country_names\n",
    "\n",
    "def booking_synonym(query):\n",
    "    synonyms = []\n",
    "    word = \"book\"\n",
    "    for syn in wordnet.synsets(word, pos=['n', 'v']):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "# Define a function to handle customer queries and generate responses\n",
    "def chatbot_response(query):\n",
    "    global name  # Declare global variable to modify name inside the function\n",
    "    \n",
    "    # Lemmatize the query\n",
    "    query_lemmas = lemmatize_sentence(query.lower())\n",
    "    names = extract_names(query)\n",
    "    country_names = extract_country_names(query)\n",
    "    booking = booking_synonym(query)\n",
    "    if \"hello\" in query_lemmas or \"hi\" in query_lemmas and (\"my\" in query_lemmas and \"name\" in query_lemmas):\n",
    "        # Check if the query includes the user's name\n",
    "        if names:\n",
    "            name = names[0]\n",
    "            return responses[\"user_Intro\"][0].format(name=name)\n",
    "        else:\n",
    "            return random.choice(responses[\"greeting\"])\n",
    "    elif \"what\" in query_lemmas and \"is\" in query_lemmas and \"my\" in query_lemmas and \"name\" in query_lemmas:\n",
    "        if name:\n",
    "            return responses[\"my_name\"][0].format(name=name)\n",
    "        else:\n",
    "            return \"I'm sorry, I didn't catch your name. Can you please tell me your name?\"\n",
    "    elif booking:\n",
    "        return responses[\"booking\"][0]\n",
    "        #elif \"country\" in query_lemmas:\n",
    "        #return responses[\"available-country\"][0]\n",
    "    elif country_names:\n",
    "        country_name = country_names[0]\n",
    "        if country_name not in asean_countries:\n",
    "            return responses[\"not_understand\"][0]\n",
    "            # Country is not in ASEAN\n",
    "            #return \"I'm sorry, we currently only support countries in ASEAN.\"\n",
    "        else:\n",
    "            for country in asean_countries:\n",
    "                if country == country_name:\n",
    "                    return responses[\"country_name\"][0].format(country_name=country_name)\n",
    "    elif \"complaint\" in query_lemmas or \"issue\" in query_lemmas:\n",
    "        return random.choice(responses[\"complaint\"])\n",
    "    elif \"support\" in query_lemmas or \"contact\" in query_lemmas:\n",
    "        return random.choice(responses[\"support_channel\"])\n",
    "    elif \"reset\" in query_lemmas or \"update\" in query_lemmas:\n",
    "        return random.choice(responses[\"task\"])\n",
    "    elif \"feedback\" in query_lemmas or \"review\" in query_lemmas:\n",
    "        return random.choice(responses[\"feedback\"])\n",
    "    else:\n",
    "        return responses[\"not_understand\"][1]\n",
    "        #return \"I'm sorry, I didn't understand your query. Please try again.\"\n",
    "\n",
    "\n",
    "# Define a function to handle user interaction\n",
    "def chatbot():\n",
    "    print(\"Welcome to our customer service chatbot!\")\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        response = chatbot_response(query)\n",
    "        print(\"Chatbot: \" + response)\n",
    "        #print(person_names)\n",
    "\n",
    "# Run the chatbot function\n",
    "chatbot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51eae007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What?Malaysia\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# sample text\n",
    "text = input(\"What?\")\n",
    "\n",
    "# tokenize the text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# use Part-of-Speech (POS) tagging to tag the words with their part of speech\n",
    "tagged_words = nltk.pos_tag(tokens)\n",
    "\n",
    "# use Named Entity Recognition (NER) to label the named entities in the text\n",
    "ner_tagged = nltk.ne_chunk(tagged_words)\n",
    "\n",
    "# iterate over the entities and print the country names\n",
    "for entity in ner_tagged:\n",
    "    if hasattr(entity, 'label') and entity.label() == 'GPE':\n",
    "        if len(entity.leaves()) == 1 and entity.leaves()[0][1] == 'NNP':\n",
    "            print(entity.leaves()[0][0])\n",
    "            #print(tagged_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f562aca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "Using Nominatim with default or sample `user_agent` \"my-application\" is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28280\\187194104.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# instantiate a geolocator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgeolocator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"my-application\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# tokenize the text and perform named entity recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, timeout, proxies, domain, scheme, user_agent, ssl_context, adapter_factory)\u001b[0m\n\u001b[0;32m    103\u001b[0m         if (self.domain == _DEFAULT_NOMINATIM_DOMAIN\n\u001b[0;32m    104\u001b[0m                 and self.headers['User-Agent'] in _REJECTED_USER_AGENTS):\n\u001b[1;32m--> 105\u001b[1;33m             raise ConfigurationError(\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;34m'Using Nominatim with default or sample `user_agent` \"%s\" is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[1;34m'strongly discouraged, as it violates Nominatim\\'s ToS '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConfigurationError\u001b[0m: Using Nominatim with default or sample `user_agent` \"my-application\" is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# sample text\n",
    "text = \"I am planning a trip to Singapore, Malaysia, and Thailand.\"\n",
    "\n",
    "# instantiate a geolocator\n",
    "geolocator = Nominatim(user_agent=\"my-application\")\n",
    "\n",
    "# tokenize the text and perform named entity recognition\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "chunks = nltk.ne_chunk(tags)\n",
    "\n",
    "# create a set of Southeast Asian country names\n",
    "se_asia = set(['Brunei', 'Cambodia', 'Indonesia', 'Laos', 'Malaysia', 'Myanmar', 'Philippines', 'Singapore', 'Thailand', 'Timor-Leste', 'Vietnam'])\n",
    "\n",
    "# extract the country names from the named entity chunks\n",
    "countries = []\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk, 'label') and chunk.label() == 'GPE':\n",
    "        country = ' '.join(c[0] for c in chunk.leaves())\n",
    "        if country in se_asia:\n",
    "            countries.append(country)\n",
    "\n",
    "print(countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0b2117",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16400\\3614015878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0masean_countries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Brunei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cambodia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Indonesia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Laos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Malaysia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Myanmar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Philippines'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Singapore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Thailand'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Vietnam'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masean_countries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "asean_countries = {'Brunei', 'Cambodia', 'Indonesia', 'Laos', 'Malaysia', 'Myanmar', 'Philippines', 'Singapore', 'Thailand', 'Vietnam'}\n",
    "\n",
    "print(asean_countries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443ae73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want:book\n",
      "{'Book', 'record', 'Holy_Writ', 'account_book', 'rule_book', 'reserve', 'Bible', \"al-Qur'an\", 'script', 'book', 'record_book', 'Scripture', 'Holy_Scripture', 'book_of_account', 'Quran', 'Good_Book', 'leger', 'volume', 'playscript', 'ledger', 'Word', 'Christian_Bible', 'hold', 'Word_of_God', 'Koran'}\n",
      "Yes\n",
      "What do you want:booking\n",
      "{'Book', 'record', 'Holy_Writ', 'account_book', 'rule_book', 'reserve', 'Bible', \"al-Qur'an\", 'script', 'book', 'record_book', 'Scripture', 'Holy_Scripture', 'book_of_account', 'Quran', 'Good_Book', 'leger', 'volume', 'playscript', 'ledger', 'Word', 'Christian_Bible', 'hold', 'Word_of_God', 'Koran'}\n",
      "No\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12564\\527171500.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"What do you want:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"book\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msynonyms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "while True:\n",
    "    words = input(\"What do you want:\")\n",
    "    word = \"book\"\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word, pos=['n', 'v']):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "\n",
    "    if words == \"exit\":\n",
    "        break\n",
    "    print(set(synonyms))\n",
    "    if words.lower() in set(synonyms):\n",
    "        print(\"Yes\")\n",
    "    else:\n",
    "        print(\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b5600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f9b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
